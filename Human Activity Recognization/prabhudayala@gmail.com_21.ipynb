{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\user\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initiliazing the sequential model\n",
    "# model = Sequential()\n",
    "# # Configuring the parameters\n",
    "# model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# # Adding a dropout layer\n",
    "# model.add(Dropout(0.5))\n",
    "# # Adding a dense output layer with sigmoid activation\n",
    "# model.add(Dense(n_classes, activation='sigmoid'))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compiling the model\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training the model\n",
    "# from datetime import datetime\n",
    "# print(datetime.now())\n",
    "# model.fit(X_train,\n",
    "#           Y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           validation_data=(X_test, Y_test),\n",
    "#           epochs=epochs)\n",
    "# print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Confusion Matrix\n",
    "# print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a simple 2 layer architecture we got 90.09% accuracy and a loss of 0.30\n",
    "- We can further imporve the performace with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1023 23:43:42.524905  1276 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1023 23:43:42.526900  1276 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:519: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1023 23:43:42.529892  1276 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4140: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1023 23:43:42.744337  1276 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1023 23:43:42.753314  1276 deprecation.py:506] From C:\\Users\\user\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3447: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1023 23:43:42.754310  1276 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1023 23:43:43.053268  1276 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1023 23:43:43.084184  1276 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1023 23:43:43.110115  1276 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3297: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1023 23:43:43.239768  1276 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128, 100)          44000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 125,006\n",
      "Trainable params: 125,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2019-10-23 23:43:43.130061\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/50\n",
      "7352/7352 [==============================] - 99s 13ms/step - loss: 1.1495 - acc: 0.4973 - val_loss: 0.9139 - val_acc: 0.5891\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.58907, saving model to weights-improvement-model1.hdf5\n",
      "Epoch 2/50\n",
      "7352/7352 [==============================] - 97s 13ms/step - loss: 0.8102 - acc: 0.6055 - val_loss: 0.7867 - val_acc: 0.5881\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.58907\n",
      "Epoch 3/50\n",
      "7352/7352 [==============================] - 126s 17ms/step - loss: 0.7107 - acc: 0.6595 - val_loss: 0.7640 - val_acc: 0.6810\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.58907 to 0.68103, saving model to weights-improvement-model1.hdf5\n",
      "Epoch 4/50\n",
      "7352/7352 [==============================] - 159s 22ms/step - loss: 0.7212 - acc: 0.6593 - val_loss: 0.8491 - val_acc: 0.5979\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.68103\n",
      "Epoch 5/50\n",
      "7352/7352 [==============================] - 203s 28ms/step - loss: 0.7137 - acc: 0.6711 - val_loss: 0.7349 - val_acc: 0.6946\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.68103 to 0.69460, saving model to weights-improvement-model1.hdf5\n",
      "Epoch 6/50\n",
      "7352/7352 [==============================] - 201s 27ms/step - loss: 0.6485 - acc: 0.6927 - val_loss: 0.7264 - val_acc: 0.6848\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.69460\n",
      "Epoch 7/50\n",
      "7352/7352 [==============================] - 206s 28ms/step - loss: 0.6392 - acc: 0.7078 - val_loss: 0.7728 - val_acc: 0.6552\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.69460\n",
      "Epoch 8/50\n",
      "7352/7352 [==============================] - 206s 28ms/step - loss: 0.5895 - acc: 0.7149 - val_loss: 0.6374 - val_acc: 0.7251\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.69460 to 0.72514, saving model to weights-improvement-model1.hdf5\n",
      "Epoch 9/50\n",
      "7352/7352 [==============================] - 210s 29ms/step - loss: 0.4777 - acc: 0.7912 - val_loss: 0.7598 - val_acc: 0.7387\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.72514 to 0.73872, saving model to weights-improvement-model1.hdf5\n",
      "Epoch 10/50\n",
      "7352/7352 [==============================] - 210s 29ms/step - loss: 0.3275 - acc: 0.8795 - val_loss: 0.6216 - val_acc: 0.8198\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.73872 to 0.81982, saving model to weights-improvement-model1.hdf5\n",
      "Epoch 11/50\n",
      "7352/7352 [==============================] - 206s 28ms/step - loss: 0.2236 - acc: 0.9248 - val_loss: 0.4046 - val_acc: 0.9033\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.81982 to 0.90329, saving model to weights-improvement-model1.hdf5\n",
      "Epoch 12/50\n",
      "7352/7352 [==============================] - 144s 20ms/step - loss: 0.1764 - acc: 0.9392 - val_loss: 0.4191 - val_acc: 0.9080\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.90329 to 0.90804, saving model to weights-improvement-model1.hdf5\n",
      "Epoch 13/50\n",
      "7352/7352 [==============================] - 106s 14ms/step - loss: 0.1698 - acc: 0.9416 - val_loss: 0.4965 - val_acc: 0.8853\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.90804\n",
      "Epoch 14/50\n",
      "7352/7352 [==============================] - 111s 15ms/step - loss: 0.1695 - acc: 0.9385 - val_loss: 0.5351 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.90804\n",
      "Epoch 15/50\n",
      "7352/7352 [==============================] - 204s 28ms/step - loss: 0.1515 - acc: 0.9474 - val_loss: 0.4908 - val_acc: 0.8989\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.90804\n",
      "Epoch 16/50\n",
      "7352/7352 [==============================] - 217s 30ms/step - loss: 0.1496 - acc: 0.9474 - val_loss: 0.4761 - val_acc: 0.9131\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.90804 to 0.91313, saving model to weights-improvement-model1.hdf5\n",
      "Epoch 17/50\n",
      "7352/7352 [==============================] - 229s 31ms/step - loss: 0.1427 - acc: 0.9475 - val_loss: 0.3000 - val_acc: 0.9237\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.91313 to 0.92365, saving model to weights-improvement-model1.hdf5\n",
      "Epoch 18/50\n",
      "7352/7352 [==============================] - 219s 30ms/step - loss: 0.1402 - acc: 0.9505 - val_loss: 0.4258 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.92365\n",
      "Epoch 19/50\n",
      "7352/7352 [==============================] - 214s 29ms/step - loss: 0.1515 - acc: 0.9486 - val_loss: 0.3171 - val_acc: 0.9108\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.92365\n",
      "Epoch 20/50\n",
      "7352/7352 [==============================] - 221s 30ms/step - loss: 0.1388 - acc: 0.9478 - val_loss: 0.4456 - val_acc: 0.8918\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.92365\n",
      "Epoch 21/50\n",
      "7352/7352 [==============================] - 215s 29ms/step - loss: 0.1456 - acc: 0.9483 - val_loss: 0.6249 - val_acc: 0.8894\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.92365\n",
      "Epoch 22/50\n",
      "7352/7352 [==============================] - 185s 25ms/step - loss: 0.1440 - acc: 0.9452 - val_loss: 0.2952 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.92365\n",
      "Epoch 23/50\n",
      "7352/7352 [==============================] - 107s 15ms/step - loss: 0.1692 - acc: 0.9455 - val_loss: 0.2908 - val_acc: 0.9277\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.92365 to 0.92772, saving model to weights-improvement-model1.hdf5\n",
      "Epoch 24/50\n",
      "7352/7352 [==============================] - 199s 27ms/step - loss: 0.1294 - acc: 0.9480 - val_loss: 0.5060 - val_acc: 0.9108\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.92772\n",
      "Epoch 25/50\n",
      "7352/7352 [==============================] - 206s 28ms/step - loss: 0.1726 - acc: 0.9434 - val_loss: 0.3388 - val_acc: 0.9138\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.92772\n",
      "Epoch 26/50\n",
      "7352/7352 [==============================] - 222s 30ms/step - loss: 0.1356 - acc: 0.9516 - val_loss: 0.3752 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.92772\n",
      "Epoch 27/50\n",
      "7352/7352 [==============================] - 227s 31ms/step - loss: 0.1391 - acc: 0.9465 - val_loss: 0.4098 - val_acc: 0.9094\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.92772\n",
      "Epoch 28/50\n",
      "7352/7352 [==============================] - 240s 33ms/step - loss: 0.1396 - acc: 0.9510 - val_loss: 0.7434 - val_acc: 0.8955\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.92772\n",
      "Epoch 29/50\n",
      "7352/7352 [==============================] - 234s 32ms/step - loss: 0.1220 - acc: 0.9457 - val_loss: 0.3609 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.92772\n",
      "Epoch 30/50\n",
      "7352/7352 [==============================] - 150s 20ms/step - loss: 0.1314 - acc: 0.9453 - val_loss: 0.2820 - val_acc: 0.9335\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.92772 to 0.93349, saving model to weights-improvement-model1.hdf5\n",
      "Epoch 31/50\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.1229 - acc: 0.9506 - val_loss: 0.3978 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.93349\n",
      "Epoch 32/50\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.1494 - acc: 0.9459 - val_loss: 0.4179 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.93349\n",
      "Epoch 33/50\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.1411 - acc: 0.9501 - val_loss: 0.5865 - val_acc: 0.9101\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.93349\n",
      "Epoch 34/50\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1541 - acc: 0.9475 - val_loss: 0.7124 - val_acc: 0.9057\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.93349\n",
      "Epoch 35/50\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.1379 - acc: 0.9489 - val_loss: 0.3660 - val_acc: 0.9230\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.93349\n",
      "Epoch 36/50\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1209 - acc: 0.9520 - val_loss: 0.3120 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.93349\n",
      "Epoch 37/50\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1262 - acc: 0.9510 - val_loss: 0.4274 - val_acc: 0.9108\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.93349\n",
      "Epoch 38/50\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.1435 - acc: 0.9502 - val_loss: 0.4960 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.93349\n",
      "Epoch 39/50\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 1.3615 - acc: 0.3693 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.93349\n",
      "Epoch 40/50\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.93349\n",
      "Epoch 41/50\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.93349\n",
      "Epoch 42/50\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.93349\n",
      "Epoch 43/50\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.93349\n",
      "Epoch 44/50\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.93349\n",
      "Epoch 45/50\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.93349\n",
      "Epoch 46/50\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.93349\n",
      "Epoch 47/50\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.93349\n",
      "Epoch 48/50\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.93349\n",
      "Epoch 49/50\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.93349\n",
      "Epoch 50/50\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 1.7918 - acc: 0.1668 - val_loss: 1.7912 - val_acc: 0.1683\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.93349\n",
      "2019-10-24 01:42:10.829501\n",
      "Pred                STANDING  WALKING\n",
      "True                                 \n",
      "LAYING                     0      537\n",
      "SITTING                    0      491\n",
      "STANDING                   0      532\n",
      "WALKING                    0      496\n",
      "WALKING_DOWNSTAIRS         0      420\n",
      "WALKING_UPSTAIRS           1      470\n",
      "2947/2947 [==============================] - 10s 3ms/step\n",
      "[1.7911514966496784, 0.168306752629793]\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "n_hidden = 64\n",
    "\n",
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(100, input_shape=(timesteps, input_dim),return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.7))\n",
    "\n",
    "model.add(LSTM(100, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.7))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "filepath=\"weights-improvement-model1.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, verbose=1,monitor=\"val_acc\", save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Training the model\n",
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs,callbacks=callbacks_list)\n",
    "print(datetime.now())\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1024 09:42:27.783489  2208 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1024 09:42:27.958022  2208 nn_ops.py:4224] Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W1024 09:42:28.253257  2208 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  7      415        52        0                   0   \n",
      "STANDING                 0       73       456        1                   0   \n",
      "WALKING                  0        4         0      472                   5   \n",
      "WALKING_DOWNSTAIRS       0        0         0        1                 418   \n",
      "WALKING_UPSTAIRS         0        0         0       14                   4   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                           17  \n",
      "STANDING                           2  \n",
      "WALKING                           15  \n",
      "WALKING_DOWNSTAIRS                 1  \n",
      "WALKING_UPSTAIRS                 453  \n",
      "2947/2947 [==============================] - 11s 4ms/step\n",
      "[0.28196676261670406, 0.9334916864608076]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model1 = load_model('weights-improvement-model1.hdf5')\n",
    "print(confusion_matrix(Y_test, model1.predict(X_test)))\n",
    "score = model1.evaluate(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 128, 9)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 122, 128)          8192      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 34, 64)            57408     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 11, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 11, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 704)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                22560     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 88,358\n",
      "Trainable params: 88,358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1024 09:35:53.982462  2208 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:988: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/300\n",
      "7352/7352 [==============================] - 4s 571us/step - loss: 0.1242 - acc: 0.4820 - val_loss: 0.0874 - val_acc: 0.6220\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.62199, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 2/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0683 - acc: 0.7146 - val_loss: 0.0665 - val_acc: 0.7492\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.62199 to 0.74924, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 3/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0508 - acc: 0.8240 - val_loss: 0.0560 - val_acc: 0.7981\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.74924 to 0.79810, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 4/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0360 - acc: 0.8889 - val_loss: 0.0443 - val_acc: 0.8476\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.79810 to 0.84764, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 5/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0254 - acc: 0.9237 - val_loss: 0.0374 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.84764 to 0.86664, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 6/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0204 - acc: 0.9354 - val_loss: 0.0332 - val_acc: 0.8843\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.86664 to 0.88429, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 7/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0175 - acc: 0.9425 - val_loss: 0.0317 - val_acc: 0.8789\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.88429\n",
      "Epoch 8/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0160 - acc: 0.9461 - val_loss: 0.0295 - val_acc: 0.8884\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.88429 to 0.88836, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 9/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0148 - acc: 0.9486 - val_loss: 0.0280 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.88836 to 0.89243, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 10/300\n",
      "7352/7352 [==============================] - 1s 147us/step - loss: 0.0142 - acc: 0.9487 - val_loss: 0.0278 - val_acc: 0.8968\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.89243 to 0.89684, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 11/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0136 - acc: 0.9493 - val_loss: 0.0271 - val_acc: 0.8928\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.89684\n",
      "Epoch 12/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0130 - acc: 0.9517 - val_loss: 0.0264 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.89684 to 0.90092, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 13/300\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 0.0128 - acc: 0.9512 - val_loss: 0.0250 - val_acc: 0.9002\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.90092\n",
      "Epoch 14/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0125 - acc: 0.9521 - val_loss: 0.0247 - val_acc: 0.9091\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.90092 to 0.90906, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 15/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0123 - acc: 0.9535 - val_loss: 0.0242 - val_acc: 0.9016\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.90906\n",
      "Epoch 16/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0120 - acc: 0.9543 - val_loss: 0.0241 - val_acc: 0.9084\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.90906\n",
      "Epoch 17/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0117 - acc: 0.9553 - val_loss: 0.0232 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.90906\n",
      "Epoch 18/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0114 - acc: 0.9554 - val_loss: 0.0230 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.90906\n",
      "Epoch 19/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0113 - acc: 0.9548 - val_loss: 0.0228 - val_acc: 0.9135\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.90906 to 0.91347, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 20/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0110 - acc: 0.9569 - val_loss: 0.0220 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.91347 to 0.91415, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 21/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0109 - acc: 0.9565 - val_loss: 0.0216 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.91415 to 0.91585, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 22/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0109 - acc: 0.9574 - val_loss: 0.0212 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.91585 to 0.91619, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 23/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0107 - acc: 0.9587 - val_loss: 0.0208 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.91619 to 0.91754, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 24/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0104 - acc: 0.9584 - val_loss: 0.0205 - val_acc: 0.9216\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.91754 to 0.92162, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 25/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0103 - acc: 0.9589 - val_loss: 0.0207 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.92162\n",
      "Epoch 26/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0104 - acc: 0.9573 - val_loss: 0.0211 - val_acc: 0.9199\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.92162\n",
      "Epoch 27/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0103 - acc: 0.9581 - val_loss: 0.0218 - val_acc: 0.9070\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.92162\n",
      "Epoch 28/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0103 - acc: 0.9576 - val_loss: 0.0205 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.92162\n",
      "Epoch 29/300\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 0.0100 - acc: 0.9596 - val_loss: 0.0214 - val_acc: 0.9243\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.92162 to 0.92433, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 30/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0100 - acc: 0.9603 - val_loss: 0.0201 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.92433\n",
      "Epoch 31/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0098 - acc: 0.9603 - val_loss: 0.0206 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.92433\n",
      "Epoch 32/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0097 - acc: 0.9630 - val_loss: 0.0206 - val_acc: 0.9223\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.92433\n",
      "Epoch 33/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0096 - acc: 0.9615 - val_loss: 0.0205 - val_acc: 0.9220\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.92433\n",
      "Epoch 34/300\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0094 - acc: 0.9627 - val_loss: 0.0207 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.92433\n",
      "Epoch 35/300\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 0.0092 - acc: 0.9614 - val_loss: 0.0197 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.92433\n",
      "Epoch 36/300\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 0.0092 - acc: 0.9640 - val_loss: 0.0194 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.92433 to 0.93180, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 37/300\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 0.0092 - acc: 0.9635 - val_loss: 0.0192 - val_acc: 0.9298\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.93180\n",
      "Epoch 38/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0089 - acc: 0.9648 - val_loss: 0.0200 - val_acc: 0.9243\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.93180\n",
      "Epoch 39/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0089 - acc: 0.9635 - val_loss: 0.0187 - val_acc: 0.9281\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.93180\n",
      "Epoch 40/300\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0089 - acc: 0.9646 - val_loss: 0.0191 - val_acc: 0.9253\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.93180\n",
      "Epoch 41/300\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0086 - acc: 0.9641 - val_loss: 0.0186 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.93180\n",
      "Epoch 42/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0082 - acc: 0.9671 - val_loss: 0.0199 - val_acc: 0.9162\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.93180\n",
      "Epoch 43/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0083 - acc: 0.9675 - val_loss: 0.0185 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.93180 to 0.93519, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 44/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0081 - acc: 0.9676 - val_loss: 0.0174 - val_acc: 0.9372\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.93519 to 0.93722, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 45/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0079 - acc: 0.9674 - val_loss: 0.0163 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.93722\n",
      "Epoch 46/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0076 - acc: 0.9694 - val_loss: 0.0178 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.93722\n",
      "Epoch 47/300\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0076 - acc: 0.9703 - val_loss: 0.0159 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.93722 to 0.93756, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 48/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0074 - acc: 0.9723 - val_loss: 0.0179 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.93756\n",
      "Epoch 49/300\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0072 - acc: 0.9723 - val_loss: 0.0169 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.93756\n",
      "Epoch 50/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0070 - acc: 0.9748 - val_loss: 0.0162 - val_acc: 0.9369\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.93756\n",
      "Epoch 51/300\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 0.0068 - acc: 0.9742 - val_loss: 0.0157 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.93756 to 0.93960, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 52/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0067 - acc: 0.9757 - val_loss: 0.0163 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.93960\n",
      "Epoch 53/300\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0065 - acc: 0.9747 - val_loss: 0.0162 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.93960 to 0.94164, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 54/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0065 - acc: 0.9763 - val_loss: 0.0153 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.94164 to 0.94333, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 55/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0062 - acc: 0.9771 - val_loss: 0.0156 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.94333\n",
      "Epoch 56/300\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 0.0063 - acc: 0.9770 - val_loss: 0.0148 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.94333 to 0.94537, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 57/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0060 - acc: 0.9770 - val_loss: 0.0153 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.94537\n",
      "Epoch 58/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0059 - acc: 0.9782 - val_loss: 0.0164 - val_acc: 0.9386\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.94537\n",
      "Epoch 59/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0057 - acc: 0.9780 - val_loss: 0.0157 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.94537\n",
      "Epoch 60/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0060 - acc: 0.9771 - val_loss: 0.0162 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.94537\n",
      "Epoch 61/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0054 - acc: 0.9784 - val_loss: 0.0153 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.94537\n",
      "Epoch 62/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0054 - acc: 0.9793 - val_loss: 0.0160 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.94537\n",
      "Epoch 63/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0054 - acc: 0.9789 - val_loss: 0.0171 - val_acc: 0.9369\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.94537\n",
      "Epoch 64/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0053 - acc: 0.9791 - val_loss: 0.0157 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.94537\n",
      "Epoch 65/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0052 - acc: 0.9812 - val_loss: 0.0174 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.94537\n",
      "Epoch 66/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0052 - acc: 0.9799 - val_loss: 0.0157 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.94537\n",
      "Epoch 67/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0049 - acc: 0.9826 - val_loss: 0.0148 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.94537 to 0.94740, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 68/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0051 - acc: 0.9803 - val_loss: 0.0142 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.94740 to 0.95080, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 69/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0048 - acc: 0.9810 - val_loss: 0.0149 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.95080\n",
      "Epoch 70/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0047 - acc: 0.9822 - val_loss: 0.0152 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.95080\n",
      "Epoch 71/300\n",
      "7352/7352 [==============================] - 1s 146us/step - loss: 0.0045 - acc: 0.9819 - val_loss: 0.0151 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.95080\n",
      "Epoch 72/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0046 - acc: 0.9822 - val_loss: 0.0158 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.95080\n",
      "Epoch 73/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0045 - acc: 0.9827 - val_loss: 0.0147 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.95080\n",
      "Epoch 74/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0044 - acc: 0.9835 - val_loss: 0.0177 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.95080\n",
      "Epoch 75/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0043 - acc: 0.9842 - val_loss: 0.0148 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.95080\n",
      "Epoch 76/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0043 - acc: 0.9835 - val_loss: 0.0157 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.95080\n",
      "Epoch 77/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0043 - acc: 0.9859 - val_loss: 0.0165 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.95080\n",
      "Epoch 78/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0040 - acc: 0.9861 - val_loss: 0.0159 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.95080\n",
      "Epoch 79/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0041 - acc: 0.9841 - val_loss: 0.0161 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.95080\n",
      "Epoch 80/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0039 - acc: 0.9848 - val_loss: 0.0160 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.95080\n",
      "Epoch 81/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0042 - acc: 0.9833 - val_loss: 0.0162 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.95080\n",
      "Epoch 82/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0040 - acc: 0.9850 - val_loss: 0.0160 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.95080\n",
      "Epoch 83/300\n",
      "7352/7352 [==============================] - 1s 146us/step - loss: 0.0038 - acc: 0.9848 - val_loss: 0.0153 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.95080\n",
      "Epoch 84/300\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 0.0038 - acc: 0.9860 - val_loss: 0.0153 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.95080\n",
      "Epoch 85/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0037 - acc: 0.9849 - val_loss: 0.0160 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.95080\n",
      "Epoch 86/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0036 - acc: 0.9868 - val_loss: 0.0165 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.95080\n",
      "Epoch 87/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0034 - acc: 0.9879 - val_loss: 0.0154 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.95080\n",
      "Epoch 88/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0034 - acc: 0.9872 - val_loss: 0.0163 - val_acc: 0.9386\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.95080\n",
      "Epoch 89/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0035 - acc: 0.9861 - val_loss: 0.0190 - val_acc: 0.9318\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.95080\n",
      "Epoch 90/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0035 - acc: 0.9867 - val_loss: 0.0158 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.95080\n",
      "Epoch 91/300\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 0.0035 - acc: 0.9868 - val_loss: 0.0154 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.95080\n",
      "Epoch 92/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0034 - acc: 0.9874 - val_loss: 0.0166 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.95080\n",
      "Epoch 93/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0034 - acc: 0.9864 - val_loss: 0.0155 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.95080\n",
      "Epoch 94/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0033 - acc: 0.9875 - val_loss: 0.0159 - val_acc: 0.9460\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.95080\n",
      "Epoch 95/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0033 - acc: 0.9869 - val_loss: 0.0182 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.95080\n",
      "Epoch 96/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0032 - acc: 0.9875 - val_loss: 0.0164 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.95080\n",
      "Epoch 97/300\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0029 - acc: 0.9888 - val_loss: 0.0156 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.95080\n",
      "Epoch 98/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0029 - acc: 0.9894 - val_loss: 0.0166 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.95080\n",
      "Epoch 99/300\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0030 - acc: 0.9887 - val_loss: 0.0150 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.95080\n",
      "Epoch 100/300\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0029 - acc: 0.9894 - val_loss: 0.0156 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.95080\n",
      "Epoch 101/300\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0029 - acc: 0.9898 - val_loss: 0.0159 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.95080\n",
      "Epoch 102/300\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0032 - acc: 0.9871 - val_loss: 0.0154 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.95080\n",
      "Epoch 103/300\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0028 - acc: 0.9899 - val_loss: 0.0182 - val_acc: 0.9372\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.95080\n",
      "Epoch 104/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 0.0028 - acc: 0.9899 - val_loss: 0.0170 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.95080\n",
      "Epoch 105/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0027 - acc: 0.9905 - val_loss: 0.0160 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.95080\n",
      "Epoch 106/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0029 - acc: 0.9883 - val_loss: 0.0182 - val_acc: 0.9311\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.95080\n",
      "Epoch 107/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0027 - acc: 0.9894 - val_loss: 0.0193 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.95080\n",
      "Epoch 108/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0028 - acc: 0.9894 - val_loss: 0.0158 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.95080\n",
      "Epoch 109/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0028 - acc: 0.9883 - val_loss: 0.0161 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.95080\n",
      "Epoch 110/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0026 - acc: 0.9898 - val_loss: 0.0160 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.95080\n",
      "Epoch 111/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0024 - acc: 0.9894 - val_loss: 0.0153 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.95080\n",
      "Epoch 112/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0026 - acc: 0.9908 - val_loss: 0.0167 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.95080\n",
      "Epoch 113/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0025 - acc: 0.9922 - val_loss: 0.0175 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.95080\n",
      "Epoch 114/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0026 - acc: 0.9908 - val_loss: 0.0152 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.95080\n",
      "Epoch 115/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0024 - acc: 0.9917 - val_loss: 0.0171 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.95080\n",
      "Epoch 116/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0025 - acc: 0.9897 - val_loss: 0.0161 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.95080\n",
      "Epoch 117/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0025 - acc: 0.9903 - val_loss: 0.0162 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.95080\n",
      "Epoch 118/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0025 - acc: 0.9893 - val_loss: 0.0177 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.95080\n",
      "Epoch 119/300\n",
      "7352/7352 [==============================] - 1s 145us/step - loss: 0.0022 - acc: 0.9918 - val_loss: 0.0171 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.95080\n",
      "Epoch 120/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0026 - acc: 0.9897 - val_loss: 0.0151 - val_acc: 0.9498\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.95080\n",
      "Epoch 121/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0023 - acc: 0.9910 - val_loss: 0.0148 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00121: val_acc improved from 0.95080 to 0.95182, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 122/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0023 - acc: 0.9906 - val_loss: 0.0164 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.95182\n",
      "Epoch 123/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 1s 140us/step - loss: 0.0023 - acc: 0.9916 - val_loss: 0.0155 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.95182\n",
      "Epoch 124/300\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 0.0022 - acc: 0.9917 - val_loss: 0.0163 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.95182\n",
      "Epoch 125/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0021 - acc: 0.9920 - val_loss: 0.0165 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.95182\n",
      "Epoch 126/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0021 - acc: 0.9924 - val_loss: 0.0159 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.95182\n",
      "Epoch 127/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0022 - acc: 0.9918 - val_loss: 0.0166 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.95182\n",
      "Epoch 128/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0018 - acc: 0.9937 - val_loss: 0.0172 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.95182\n",
      "Epoch 129/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0020 - acc: 0.9922 - val_loss: 0.0168 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.95182\n",
      "Epoch 130/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0022 - acc: 0.9924 - val_loss: 0.0156 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.95182\n",
      "Epoch 131/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0019 - acc: 0.9922 - val_loss: 0.0162 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.95182\n",
      "Epoch 132/300\n",
      "7352/7352 [==============================] - 1s 145us/step - loss: 0.0020 - acc: 0.9922 - val_loss: 0.0161 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.95182\n",
      "Epoch 133/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0020 - acc: 0.9925 - val_loss: 0.0161 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.95182\n",
      "Epoch 134/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0019 - acc: 0.9940 - val_loss: 0.0145 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.95182\n",
      "Epoch 135/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0020 - acc: 0.9917 - val_loss: 0.0158 - val_acc: 0.9460\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.95182\n",
      "Epoch 136/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0017 - acc: 0.9940 - val_loss: 0.0140 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00136: val_acc improved from 0.95182 to 0.95521, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 137/300\n",
      "7352/7352 [==============================] - 1s 147us/step - loss: 0.0020 - acc: 0.9918 - val_loss: 0.0164 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.95521\n",
      "Epoch 138/300\n",
      "7352/7352 [==============================] - 1s 149us/step - loss: 0.0019 - acc: 0.9928 - val_loss: 0.0160 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.95521\n",
      "Epoch 139/300\n",
      "7352/7352 [==============================] - 1s 150us/step - loss: 0.0017 - acc: 0.9943 - val_loss: 0.0162 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.95521\n",
      "Epoch 140/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0017 - acc: 0.9931 - val_loss: 0.0158 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.95521\n",
      "Epoch 141/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0019 - acc: 0.9927 - val_loss: 0.0164 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.95521\n",
      "Epoch 142/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0016 - acc: 0.9933 - val_loss: 0.0163 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.95521\n",
      "Epoch 143/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0018 - acc: 0.9937 - val_loss: 0.0158 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.95521\n",
      "Epoch 144/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0015 - acc: 0.9948 - val_loss: 0.0177 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.95521\n",
      "Epoch 145/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0016 - acc: 0.9939 - val_loss: 0.0152 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.95521\n",
      "Epoch 146/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.0020 - acc: 0.9918 - val_loss: 0.0167 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.95521\n",
      "Epoch 147/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0016 - acc: 0.9940 - val_loss: 0.0171 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.95521\n",
      "Epoch 148/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0015 - acc: 0.9940 - val_loss: 0.0157 - val_acc: 0.9498\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.95521\n",
      "Epoch 149/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0015 - acc: 0.9944 - val_loss: 0.0153 - val_acc: 0.9481\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.95521\n",
      "Epoch 150/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0013 - acc: 0.9955 - val_loss: 0.0155 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.95521\n",
      "Epoch 151/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0016 - acc: 0.9932 - val_loss: 0.0162 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.95521\n",
      "Epoch 152/300\n",
      "7352/7352 [==============================] - 1s 145us/step - loss: 0.0014 - acc: 0.9954 - val_loss: 0.0151 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.95521\n",
      "Epoch 153/300\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 0.0015 - acc: 0.9952 - val_loss: 0.0162 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.95521\n",
      "Epoch 154/300\n",
      "7352/7352 [==============================] - 1s 154us/step - loss: 0.0012 - acc: 0.9958 - val_loss: 0.0162 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.95521\n",
      "Epoch 155/300\n",
      "7352/7352 [==============================] - 1s 146us/step - loss: 0.0015 - acc: 0.9950 - val_loss: 0.0154 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.95521\n",
      "Epoch 156/300\n",
      "7352/7352 [==============================] - 1s 156us/step - loss: 0.0015 - acc: 0.9942 - val_loss: 0.0157 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.95521\n",
      "Epoch 157/300\n",
      "7352/7352 [==============================] - 1s 147us/step - loss: 0.0015 - acc: 0.9944 - val_loss: 0.0154 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.95521\n",
      "Epoch 158/300\n",
      "7352/7352 [==============================] - 1s 149us/step - loss: 0.0016 - acc: 0.9933 - val_loss: 0.0157 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.95521\n",
      "Epoch 159/300\n",
      "7352/7352 [==============================] - 1s 146us/step - loss: 0.0015 - acc: 0.9936 - val_loss: 0.0185 - val_acc: 0.9332\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.95521\n",
      "Epoch 160/300\n",
      "7352/7352 [==============================] - 1s 149us/step - loss: 0.0013 - acc: 0.9942 - val_loss: 0.0149 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.95521\n",
      "Epoch 161/300\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 0.0012 - acc: 0.9951 - val_loss: 0.0152 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.95521\n",
      "Epoch 162/300\n",
      "7352/7352 [==============================] - 1s 165us/step - loss: 0.0015 - acc: 0.9940 - val_loss: 0.0156 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.95521\n",
      "Epoch 163/300\n",
      "7352/7352 [==============================] - 1s 164us/step - loss: 0.0011 - acc: 0.9963 - val_loss: 0.0144 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.95521\n",
      "Epoch 164/300\n",
      "7352/7352 [==============================] - 1s 160us/step - loss: 0.0012 - acc: 0.9961 - val_loss: 0.0157 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.95521\n",
      "Epoch 165/300\n",
      "7352/7352 [==============================] - 1s 137us/step - loss: 0.0012 - acc: 0.9962 - val_loss: 0.0153 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.95521\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0012 - acc: 0.9955 - val_loss: 0.0153 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.95521\n",
      "Epoch 167/300\n",
      "7352/7352 [==============================] - 1s 137us/step - loss: 0.0013 - acc: 0.9954 - val_loss: 0.0164 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.95521\n",
      "Epoch 168/300\n",
      "7352/7352 [==============================] - 1s 137us/step - loss: 0.0010 - acc: 0.9963 - val_loss: 0.0151 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.95521\n",
      "Epoch 169/300\n",
      "7352/7352 [==============================] - 1s 137us/step - loss: 0.0011 - acc: 0.9970 - val_loss: 0.0166 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.95521\n",
      "Epoch 170/300\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 0.0012 - acc: 0.9963 - val_loss: 0.0172 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.95521\n",
      "Epoch 171/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 0.0010 - acc: 0.9969 - val_loss: 0.0151 - val_acc: 0.9498\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.95521\n",
      "Epoch 172/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0011 - acc: 0.9959 - val_loss: 0.0158 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.95521\n",
      "Epoch 173/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 9.7894e-04 - acc: 0.9961 - val_loss: 0.0145 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.95521\n",
      "Epoch 174/300\n",
      "7352/7352 [==============================] - 1s 137us/step - loss: 9.3390e-04 - acc: 0.9970 - val_loss: 0.0147 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.95521\n",
      "Epoch 175/300\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 9.7337e-04 - acc: 0.9971 - val_loss: 0.0146 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.95521\n",
      "Epoch 176/300\n",
      "7352/7352 [==============================] - 1s 137us/step - loss: 0.0011 - acc: 0.9954 - val_loss: 0.0152 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.95521\n",
      "Epoch 177/300\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 0.0011 - acc: 0.9956 - val_loss: 0.0133 - val_acc: 0.9569\n",
      "\n",
      "Epoch 00177: val_acc improved from 0.95521 to 0.95691, saving model to weights-improvement-model2.hdf5\n",
      "Epoch 178/300\n",
      "7352/7352 [==============================] - 1s 150us/step - loss: 0.0015 - acc: 0.9946 - val_loss: 0.0152 - val_acc: 0.9498\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.95691\n",
      "Epoch 179/300\n",
      "7352/7352 [==============================] - 1s 137us/step - loss: 8.8711e-04 - acc: 0.9971 - val_loss: 0.0149 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.95691\n",
      "Epoch 180/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0011 - acc: 0.9965 - val_loss: 0.0150 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.95691\n",
      "Epoch 181/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 8.3220e-04 - acc: 0.9976 - val_loss: 0.0151 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.95691\n",
      "Epoch 182/300\n",
      "7352/7352 [==============================] - 1s 137us/step - loss: 8.5491e-04 - acc: 0.9971 - val_loss: 0.0148 - val_acc: 0.9515\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.95691\n",
      "Epoch 183/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 0.0010 - acc: 0.9961 - val_loss: 0.0148 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.95691\n",
      "Epoch 184/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 7.6203e-04 - acc: 0.9976 - val_loss: 0.0148 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.95691\n",
      "Epoch 185/300\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 0.0011 - acc: 0.9959 - val_loss: 0.0153 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.95691\n",
      "Epoch 186/300\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 0.0011 - acc: 0.9961 - val_loss: 0.0158 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.95691\n",
      "Epoch 187/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 8.5008e-04 - acc: 0.9970 - val_loss: 0.0148 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.95691\n",
      "Epoch 188/300\n",
      "7352/7352 [==============================] - 1s 146us/step - loss: 8.0902e-04 - acc: 0.9971 - val_loss: 0.0148 - val_acc: 0.9481\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.95691\n",
      "Epoch 189/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.0011 - acc: 0.9955 - val_loss: 0.0150 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.95691\n",
      "Epoch 190/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 7.3452e-04 - acc: 0.9981 - val_loss: 0.0158 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.95691\n",
      "Epoch 191/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 7.4921e-04 - acc: 0.9974 - val_loss: 0.0155 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.95691\n",
      "Epoch 192/300\n",
      "7352/7352 [==============================] - 1s 145us/step - loss: 6.6976e-04 - acc: 0.9982 - val_loss: 0.0153 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.95691\n",
      "Epoch 193/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 5.8834e-04 - acc: 0.9977 - val_loss: 0.0153 - val_acc: 0.9481\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.95691\n",
      "Epoch 194/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 8.4791e-04 - acc: 0.9967 - val_loss: 0.0151 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.95691\n",
      "Epoch 195/300\n",
      "7352/7352 [==============================] - 1s 145us/step - loss: 9.5562e-04 - acc: 0.9962 - val_loss: 0.0146 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.95691\n",
      "Epoch 196/300\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 8.5319e-04 - acc: 0.9969 - val_loss: 0.0152 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.95691\n",
      "Epoch 197/300\n",
      "7352/7352 [==============================] - 1s 146us/step - loss: 9.8515e-04 - acc: 0.9962 - val_loss: 0.0157 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.95691\n",
      "Epoch 198/300\n",
      "7352/7352 [==============================] - 1s 149us/step - loss: 6.9938e-04 - acc: 0.9974 - val_loss: 0.0140 - val_acc: 0.9552\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.95691\n",
      "Epoch 199/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 6.4745e-04 - acc: 0.9980 - val_loss: 0.0145 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.95691\n",
      "Epoch 200/300\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 9.9739e-04 - acc: 0.9969 - val_loss: 0.0154 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.95691\n",
      "Epoch 201/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 7.0606e-04 - acc: 0.9978 - val_loss: 0.0150 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00201: val_acc did not improve from 0.95691\n",
      "Epoch 202/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 8.3372e-04 - acc: 0.9969 - val_loss: 0.0153 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.95691\n",
      "Epoch 203/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 7.8217e-04 - acc: 0.9976 - val_loss: 0.0162 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00203: val_acc did not improve from 0.95691\n",
      "Epoch 204/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 5.8811e-04 - acc: 0.9981 - val_loss: 0.0156 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.95691\n",
      "Epoch 205/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 6.4197e-04 - acc: 0.9984 - val_loss: 0.0166 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.95691\n",
      "Epoch 206/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 6.7785e-04 - acc: 0.9980 - val_loss: 0.0167 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.95691\n",
      "Epoch 207/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 6.2987e-04 - acc: 0.9981 - val_loss: 0.0153 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.95691\n",
      "Epoch 208/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 1s 141us/step - loss: 7.8840e-04 - acc: 0.9971 - val_loss: 0.0157 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.95691\n",
      "Epoch 209/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 5.5917e-04 - acc: 0.9982 - val_loss: 0.0152 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.95691\n",
      "Epoch 210/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 8.0988e-04 - acc: 0.9974 - val_loss: 0.0147 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.95691\n",
      "Epoch 211/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 6.4212e-04 - acc: 0.9974 - val_loss: 0.0151 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.95691\n",
      "Epoch 212/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 5.8723e-04 - acc: 0.9978 - val_loss: 0.0150 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.95691\n",
      "Epoch 213/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 7.8247e-04 - acc: 0.9971 - val_loss: 0.0166 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.95691\n",
      "Epoch 214/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 5.1736e-04 - acc: 0.9982 - val_loss: 0.0156 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.95691\n",
      "Epoch 215/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 6.1195e-04 - acc: 0.9978 - val_loss: 0.0158 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.95691\n",
      "Epoch 216/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 4.4531e-04 - acc: 0.9988 - val_loss: 0.0156 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.95691\n",
      "Epoch 217/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 9.8012e-04 - acc: 0.9963 - val_loss: 0.0153 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00217: val_acc did not improve from 0.95691\n",
      "Epoch 218/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 6.3245e-04 - acc: 0.9982 - val_loss: 0.0158 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00218: val_acc did not improve from 0.95691\n",
      "Epoch 219/300\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 7.9037e-04 - acc: 0.9973 - val_loss: 0.0155 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00219: val_acc did not improve from 0.95691\n",
      "Epoch 220/300\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 7.1192e-04 - acc: 0.9973 - val_loss: 0.0150 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00220: val_acc did not improve from 0.95691\n",
      "Epoch 221/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 5.1633e-04 - acc: 0.9982 - val_loss: 0.0155 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00221: val_acc did not improve from 0.95691\n",
      "Epoch 222/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 4.2613e-04 - acc: 0.9990 - val_loss: 0.0165 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00222: val_acc did not improve from 0.95691\n",
      "Epoch 223/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 6.5953e-04 - acc: 0.9980 - val_loss: 0.0164 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00223: val_acc did not improve from 0.95691\n",
      "Epoch 224/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 4.0126e-04 - acc: 0.9988 - val_loss: 0.0168 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00224: val_acc did not improve from 0.95691\n",
      "Epoch 225/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 7.1916e-04 - acc: 0.9976 - val_loss: 0.0156 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00225: val_acc did not improve from 0.95691\n",
      "Epoch 226/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 7.0303e-04 - acc: 0.9977 - val_loss: 0.0158 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00226: val_acc did not improve from 0.95691\n",
      "Epoch 227/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 5.8921e-04 - acc: 0.9976 - val_loss: 0.0155 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00227: val_acc did not improve from 0.95691\n",
      "Epoch 228/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 5.1887e-04 - acc: 0.9982 - val_loss: 0.0177 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00228: val_acc did not improve from 0.95691\n",
      "Epoch 229/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 5.5064e-04 - acc: 0.9982 - val_loss: 0.0161 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00229: val_acc did not improve from 0.95691\n",
      "Epoch 230/300\n",
      "7352/7352 [==============================] - 1s 145us/step - loss: 4.9864e-04 - acc: 0.9982 - val_loss: 0.0152 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00230: val_acc did not improve from 0.95691\n",
      "Epoch 231/300\n",
      "7352/7352 [==============================] - 1s 145us/step - loss: 3.9278e-04 - acc: 0.9989 - val_loss: 0.0183 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00231: val_acc did not improve from 0.95691\n",
      "Epoch 232/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 6.7876e-04 - acc: 0.9982 - val_loss: 0.0160 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00232: val_acc did not improve from 0.95691\n",
      "Epoch 233/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 4.1520e-04 - acc: 0.9989 - val_loss: 0.0152 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00233: val_acc did not improve from 0.95691\n",
      "Epoch 234/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 3.9254e-04 - acc: 0.9989 - val_loss: 0.0160 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00234: val_acc did not improve from 0.95691\n",
      "Epoch 235/300\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 5.7121e-04 - acc: 0.9982 - val_loss: 0.0166 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00235: val_acc did not improve from 0.95691\n",
      "Epoch 236/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 3.9723e-04 - acc: 0.9989 - val_loss: 0.0156 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00236: val_acc did not improve from 0.95691\n",
      "Epoch 237/300\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 4.7494e-04 - acc: 0.9984 - val_loss: 0.0200 - val_acc: 0.9345\n",
      "\n",
      "Epoch 00237: val_acc did not improve from 0.95691\n",
      "Epoch 238/300\n",
      "7352/7352 [==============================] - 1s 147us/step - loss: 5.2468e-04 - acc: 0.9980 - val_loss: 0.0174 - val_acc: 0.9393\n",
      "\n",
      "Epoch 00238: val_acc did not improve from 0.95691\n",
      "Epoch 239/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 5.5961e-04 - acc: 0.9982 - val_loss: 0.0154 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00239: val_acc did not improve from 0.95691\n",
      "Epoch 240/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 6.3839e-04 - acc: 0.9974 - val_loss: 0.0154 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00240: val_acc did not improve from 0.95691\n",
      "Epoch 241/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 7.7773e-04 - acc: 0.9971 - val_loss: 0.0143 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00241: val_acc did not improve from 0.95691\n",
      "Epoch 242/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 4.3959e-04 - acc: 0.9988 - val_loss: 0.0157 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00242: val_acc did not improve from 0.95691\n",
      "Epoch 243/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 3.4061e-04 - acc: 0.9992 - val_loss: 0.0160 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00243: val_acc did not improve from 0.95691\n",
      "Epoch 244/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 3.7918e-04 - acc: 0.9988 - val_loss: 0.0147 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00244: val_acc did not improve from 0.95691\n",
      "Epoch 245/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 3.7813e-04 - acc: 0.9990 - val_loss: 0.0151 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00245: val_acc did not improve from 0.95691\n",
      "Epoch 246/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 3.9888e-04 - acc: 0.9988 - val_loss: 0.0159 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00246: val_acc did not improve from 0.95691\n",
      "Epoch 247/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 6.4220e-04 - acc: 0.9977 - val_loss: 0.0159 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00247: val_acc did not improve from 0.95691\n",
      "Epoch 248/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 4.3799e-04 - acc: 0.9988 - val_loss: 0.0164 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00248: val_acc did not improve from 0.95691\n",
      "Epoch 249/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 2.8903e-04 - acc: 0.9995 - val_loss: 0.0155 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00249: val_acc did not improve from 0.95691\n",
      "Epoch 250/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 1s 144us/step - loss: 4.7730e-04 - acc: 0.9985 - val_loss: 0.0189 - val_acc: 0.9338\n",
      "\n",
      "Epoch 00250: val_acc did not improve from 0.95691\n",
      "Epoch 251/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 4.7993e-04 - acc: 0.9982 - val_loss: 0.0164 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00251: val_acc did not improve from 0.95691\n",
      "Epoch 252/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 3.3606e-04 - acc: 0.9990 - val_loss: 0.0161 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00252: val_acc did not improve from 0.95691\n",
      "Epoch 253/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 4.4670e-04 - acc: 0.9989 - val_loss: 0.0154 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00253: val_acc did not improve from 0.95691\n",
      "Epoch 254/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 4.6522e-04 - acc: 0.9985 - val_loss: 0.0186 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00254: val_acc did not improve from 0.95691\n",
      "Epoch 255/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 5.1232e-04 - acc: 0.9977 - val_loss: 0.0161 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00255: val_acc did not improve from 0.95691\n",
      "Epoch 256/300\n",
      "7352/7352 [==============================] - 1s 147us/step - loss: 8.0518e-04 - acc: 0.9970 - val_loss: 0.0171 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00256: val_acc did not improve from 0.95691\n",
      "Epoch 257/300\n",
      "7352/7352 [==============================] - 1s 152us/step - loss: 2.6289e-04 - acc: 0.9996 - val_loss: 0.0159 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00257: val_acc did not improve from 0.95691\n",
      "Epoch 258/300\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 3.1455e-04 - acc: 0.9995 - val_loss: 0.0163 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00258: val_acc did not improve from 0.95691\n",
      "Epoch 259/300\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 3.7906e-04 - acc: 0.9989 - val_loss: 0.0169 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00259: val_acc did not improve from 0.95691\n",
      "Epoch 260/300\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 3.8924e-04 - acc: 0.9986 - val_loss: 0.0159 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00260: val_acc did not improve from 0.95691\n",
      "Epoch 261/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 3.4276e-04 - acc: 0.9992 - val_loss: 0.0168 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00261: val_acc did not improve from 0.95691\n",
      "Epoch 262/300\n",
      "7352/7352 [==============================] - 1s 146us/step - loss: 6.1740e-04 - acc: 0.9974 - val_loss: 0.0163 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00262: val_acc did not improve from 0.95691\n",
      "Epoch 263/300\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 6.1783e-04 - acc: 0.9977 - val_loss: 0.0156 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00263: val_acc did not improve from 0.95691\n",
      "Epoch 264/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 5.9046e-04 - acc: 0.9977 - val_loss: 0.0149 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00264: val_acc did not improve from 0.95691\n",
      "Epoch 265/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 3.2093e-04 - acc: 0.9989 - val_loss: 0.0161 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00265: val_acc did not improve from 0.95691\n",
      "Epoch 266/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 3.2443e-04 - acc: 0.9990 - val_loss: 0.0158 - val_acc: 0.9474\n",
      "\n",
      "Epoch 00266: val_acc did not improve from 0.95691\n",
      "Epoch 267/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 2.1759e-04 - acc: 0.9995 - val_loss: 0.0177 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00267: val_acc did not improve from 0.95691\n",
      "Epoch 268/300\n",
      "7352/7352 [==============================] - 1s 151us/step - loss: 2.8062e-04 - acc: 0.9989 - val_loss: 0.0163 - val_acc: 0.9460\n",
      "\n",
      "Epoch 00268: val_acc did not improve from 0.95691\n",
      "Epoch 269/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 3.9067e-04 - acc: 0.9986 - val_loss: 0.0160 - val_acc: 0.9460\n",
      "\n",
      "Epoch 00269: val_acc did not improve from 0.95691\n",
      "Epoch 270/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 2.1390e-04 - acc: 0.9995 - val_loss: 0.0153 - val_acc: 0.9494\n",
      "\n",
      "Epoch 00270: val_acc did not improve from 0.95691\n",
      "Epoch 271/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 1.1411e-04 - acc: 0.9999 - val_loss: 0.0161 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00271: val_acc did not improve from 0.95691\n",
      "Epoch 272/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 9.7889e-04 - acc: 0.9958 - val_loss: 0.0169 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00272: val_acc did not improve from 0.95691\n",
      "Epoch 273/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 2.4410e-04 - acc: 0.9995 - val_loss: 0.0161 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00273: val_acc did not improve from 0.95691\n",
      "Epoch 274/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 4.0511e-04 - acc: 0.9984 - val_loss: 0.0163 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00274: val_acc did not improve from 0.95691\n",
      "Epoch 275/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 3.1733e-04 - acc: 0.9989 - val_loss: 0.0178 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00275: val_acc did not improve from 0.95691\n",
      "Epoch 276/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 6.2485e-04 - acc: 0.9977 - val_loss: 0.0161 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00276: val_acc did not improve from 0.95691\n",
      "Epoch 277/300\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 3.7476e-04 - acc: 0.9990 - val_loss: 0.0182 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00277: val_acc did not improve from 0.95691\n",
      "Epoch 278/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 2.4141e-04 - acc: 0.9995 - val_loss: 0.0164 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00278: val_acc did not improve from 0.95691\n",
      "Epoch 279/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 1.6657e-04 - acc: 0.9999 - val_loss: 0.0165 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00279: val_acc did not improve from 0.95691\n",
      "Epoch 280/300\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 2.8296e-04 - acc: 0.9989 - val_loss: 0.0172 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00280: val_acc did not improve from 0.95691\n",
      "Epoch 281/300\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 2.4202e-04 - acc: 0.9995 - val_loss: 0.0166 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00281: val_acc did not improve from 0.95691\n",
      "Epoch 282/300\n",
      "7352/7352 [==============================] - 1s 135us/step - loss: 3.3530e-04 - acc: 0.9989 - val_loss: 0.0175 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00282: val_acc did not improve from 0.95691\n",
      "Epoch 283/300\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 3.4441e-04 - acc: 0.9989 - val_loss: 0.0169 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00283: val_acc did not improve from 0.95691\n",
      "Epoch 284/300\n",
      "7352/7352 [==============================] - 1s 140us/step - loss: 4.0357e-04 - acc: 0.9984 - val_loss: 0.0164 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00284: val_acc did not improve from 0.95691\n",
      "Epoch 285/300\n",
      "7352/7352 [==============================] - 1s 136us/step - loss: 3.6321e-04 - acc: 0.9989 - val_loss: 0.0159 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00285: val_acc did not improve from 0.95691\n",
      "Epoch 286/300\n",
      "7352/7352 [==============================] - 1s 137us/step - loss: 1.3146e-04 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 0.9477\n",
      "\n",
      "Epoch 00286: val_acc did not improve from 0.95691\n",
      "Epoch 287/300\n",
      "7352/7352 [==============================] - 1s 138us/step - loss: 3.7253e-04 - acc: 0.9986 - val_loss: 0.0169 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00287: val_acc did not improve from 0.95691\n",
      "Epoch 288/300\n",
      "7352/7352 [==============================] - 1s 139us/step - loss: 2.4916e-04 - acc: 0.9990 - val_loss: 0.0160 - val_acc: 0.9450\n",
      "\n",
      "Epoch 00288: val_acc did not improve from 0.95691\n",
      "Epoch 289/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 3.9769e-04 - acc: 0.9985 - val_loss: 0.0149 - val_acc: 0.9481\n",
      "\n",
      "Epoch 00289: val_acc did not improve from 0.95691\n",
      "Epoch 290/300\n",
      "7352/7352 [==============================] - 1s 144us/step - loss: 5.3751e-04 - acc: 0.9980 - val_loss: 0.0174 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00290: val_acc did not improve from 0.95691\n",
      "Epoch 291/300\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 1.6893e-04 - acc: 0.9996 - val_loss: 0.0162 - val_acc: 0.9467\n",
      "\n",
      "Epoch 00291: val_acc did not improve from 0.95691\n",
      "Epoch 292/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352/7352 [==============================] - 1s 139us/step - loss: 3.2104e-04 - acc: 0.9986 - val_loss: 0.0165 - val_acc: 0.9454\n",
      "\n",
      "Epoch 00292: val_acc did not improve from 0.95691\n",
      "Epoch 293/300\n",
      "7352/7352 [==============================] - 1s 146us/step - loss: 1.3612e-04 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00293: val_acc did not improve from 0.95691\n",
      "Epoch 294/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 2.7974e-04 - acc: 0.9992 - val_loss: 0.0169 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00294: val_acc did not improve from 0.95691\n",
      "Epoch 295/300\n",
      "7352/7352 [==============================] - 1s 153us/step - loss: 2.1023e-04 - acc: 0.9992 - val_loss: 0.0164 - val_acc: 0.9464\n",
      "\n",
      "Epoch 00295: val_acc did not improve from 0.95691\n",
      "Epoch 296/300\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 1.9429e-04 - acc: 0.9997 - val_loss: 0.0175 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00296: val_acc did not improve from 0.95691\n",
      "Epoch 297/300\n",
      "7352/7352 [==============================] - 1s 141us/step - loss: 5.9529e-04 - acc: 0.9977 - val_loss: 0.0152 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00297: val_acc did not improve from 0.95691\n",
      "Epoch 298/300\n",
      "7352/7352 [==============================] - 1s 146us/step - loss: 1.7620e-04 - acc: 0.9997 - val_loss: 0.0167 - val_acc: 0.9440\n",
      "\n",
      "Epoch 00298: val_acc did not improve from 0.95691\n",
      "Epoch 299/300\n",
      "7352/7352 [==============================] - 1s 151us/step - loss: 2.8918e-04 - acc: 0.9992 - val_loss: 0.0167 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00299: val_acc did not improve from 0.95691\n",
      "Epoch 300/300\n",
      "7352/7352 [==============================] - 1s 149us/step - loss: 2.2707e-04 - acc: 0.9995 - val_loss: 0.0168 - val_acc: 0.9447\n",
      "\n",
      "Epoch 00300: val_acc did not improve from 0.95691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a06e08be0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "epochs = 300\n",
    "batch_size = 32\n",
    "n_hidden = 128\n",
    "from keras.layers import BatchNormalization,Conv1D,Flatten,MaxPooling1D,Input,Embedding\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "from keras.initializers import glorot_normal\n",
    "\n",
    "#Configuring the parameters\n",
    "\n",
    "inputIs = Input(shape=(timesteps, input_dim))\n",
    "\n",
    "model = Conv1D(128, 7, activation='relu')(inputIs)\n",
    "model = MaxPooling1D(3)(model)\n",
    "model = Dropout(0.3)(model)\n",
    "\n",
    "model = Conv1D(64, 7, activation='relu')(model)\n",
    "model = MaxPooling1D(3)(model)\n",
    "model = Dropout(0.3)(model)\n",
    "\n",
    "model = Flatten()(model)\n",
    "model = Dense(32, activation='relu')(model)\n",
    "output1 = Dense(6, activation='sigmoid')(model)\n",
    "\n",
    "\n",
    "\n",
    "model_final = Model(inputs= [inputIs], outputs=[output1])\n",
    "print(model_final.summary())\n",
    "\n",
    "# Compiling the model\n",
    "model_final.compile(loss='mean_squared_error',\n",
    "              optimizer=Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "filepath=\"weights-improvement-model2.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, verbose=1,monitor=\"val_acc\", save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "# Training the model\n",
    "model_final.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs,callbacks=callbacks_list)\n",
    "#print(confusion_matrix(Y_test, model_final.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  0      409        71        0                   0   \n",
      "STANDING                 0       39       492        1                   0   \n",
      "WALKING                  0        0         0      494                   1   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 419   \n",
      "WALKING_UPSTAIRS         0        0         0        0                   2   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                           11  \n",
      "STANDING                           0  \n",
      "WALKING                            1  \n",
      "WALKING_DOWNSTAIRS                 1  \n",
      "WALKING_UPSTAIRS                 469  \n",
      "2947/2947 [==============================] - 0s 93us/step\n",
      "[0.013335462281730605, 0.9569053274516457]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model2 = load_model('weights-improvement-model2.hdf5')\n",
    "print(confusion_matrix(Y_test, model2.predict(X_test)))\n",
    "score = model2.evaluate(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------------------------+---------+---------------+\n",
      "|  Model  |             Description              | dropout | test accuracy |\n",
      "+---------+--------------------------------------+---------+---------------+\n",
      "| Model 1 |  2 LSTM layers with 100 hidden unit  |   0.7   |     0.9334    |\n",
      "| Model 2 | 2 convolution layer with max pooling |   0.3   |     0.9569    |\n",
      "+---------+--------------------------------------+---------+---------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Model\", \"Description\", \"dropout\", \"test accuracy\"]\n",
    "x.add_row([\"Model 1\", \"2 LSTM layers with 100 hidden unit\", \"0.7\", 0.9334])\n",
    "x.add_row([\"Model 2\", \"2 convolution layer with max pooling\", \"0.3\", 0.9569])\n",
    "\n",
    "x.border=True\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
